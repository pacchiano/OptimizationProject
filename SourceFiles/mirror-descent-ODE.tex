In the following section, we combine the insights of the Nesterov continuous-time ODE in \cite{su2014differential} with the dual space framework of mirror descent to provide an elegant derivation of mirror descent and accelerated mirror descent, following the work of \cite{krichene2015accelerated}. The result is a general family of ODEs that can be discretized to obtain accelerated descent methods, demonstrating the broad application and utility of the contiuous-time viewpoint. However, we see that the proof techniques, particularly in the discretization process, become complex as we move away from the Euclidean setting, showing the limitations of the continuous-time viewpoint and highlighting the area with the most significant future work to be done. 

\subsection{Mirror Descent in Continuous Time}

To view mirror descent from a continuous time perspective, we leverage the insights gained in contiuous time. This saves us from having to take the limit of the discrete-time mirror descent algorithm (ref 5.4), which is viewed in variational form and therefore would present more of a challenge. We begin by generalizing the Lyapunov, or energy, function (ref 3.2) by replacing the $\ell_2$ norm with a Bregman divergence on dual variables, essentially treating it as a generator for first order methods. Note that $\Phi^*$ represents the dual map to $\Phi$, where $(\nabla \Phi)^{-1} = \nabla \Phi^*$, so we expect that $X = \nabla \Phi ^* (Z)$
\begin{align*}
\mathcal{E}(X(t), Z(t), t) = t(f(X(t)) - f(x^*)) + D_{\Phi^*} (Z(t), z^*)
\end{align*}
The proposed function is clearly nonnegative, but the dynamics on the variables $X$ and $Z$ must be set carefully to ensure that $\mathcal{E}$ is decreasing along trajectories of the system, thus meeting the criteria for a Lyapunov function. We therefore examine the time derivative (TODO in previous section mention derivative)
\begin{align*}
\dot {\mathcal{E}} &= (f(X(t)) - f(x^*)) + t\langle \nabla f(X(t)), \dot X(t) \rangle +  \langle \nabla \Phi^* (Z(t)) -  \nabla \Phi^* (z^*), \dot{Z}(t) \rangle\\
&= (f(X(t)) - f(x^*)) + t\langle \nabla f(X(t)), \frac{d}{dt}\nabla\Phi^*(Z(t)) \rangle + \langle X(t) -  x^*, \dot{Z}(t) \rangle\\
&= (f(X(t)) - f(x^*)) + t\langle\nabla f(X(t)), \langle \nabla^2\Phi^*(Z(t)), \dot Z(t) \rangle \rangle + \langle -\nabla f(X(t)), X(t) -  x^* \rangle \\
& \leq (f(X(t)) - f(x^*)) + t\langle\nabla f(X(t)), - \langle \nabla^2\Phi^*(Z(t)), \nabla f(X(t)) \rangle \rangle -(f(X(t)) - f(x^*))\\
& =  -t\langle  \langle \nabla^2\Phi^*(Z(t)), \nabla f(X(t)) \rangle,\nabla f(X(t))  \rangle \leq 0
\end{align*}
The above is kind of messy and below is much more elegant, but slightly less consistent with the cases presented previously. 
\begin{align*}
\dot {\mathcal{E}} &= \langle \nabla \Phi^* (Z(t)) -  \nabla \Phi^* (z^*), \dot{Z}(t) \rangle\\
&=\langle X(t) -  x^*, \dot{Z}(t) \rangle\\
&= \langle -\nabla f(X(t)), X(t) -  x^* \rangle \leq -(f(X(t)) - f(x^*))
\end{align*}
where in the last line we constrain the dynamics such that $\dot Z(t) = -\nabla f(X(t))$ and then use the convexity of $f$. Therefore, the mirror descent ODE system is found to be
\begin{align*}
&X = \nabla \Phi^*(Z)\\
&\dot Z = - \nabla f(X)\\
& Z(0) = z_0,~X(0) = \nabla \Phi^*(z_0) := x_0
\end{align*}
By the construction of this Lyapunov function, we can easily show the $1/t$ convergence rate, as above (cite previous section on using Lyapunov for showing convergence rate).

Finally, the connection between this continuous-time ODE and the mirror decsent algorithm is seen in discretizing with step size $s$. Let $t_k = sk$ and $x_k = X(t_k) = X(sk)$, then use the Euler method to say that $\dot Z = \frac{Z(t_s + s) - Z(t_s)}{s}$, and we arrive at
\begin{align*}
&x_k = \nabla \Phi^*(z_k),~z_{k+1} = z_k - s \nabla f(x_k)\\
&\implies \nabla \Phi(x_{k+1}) = \nabla \Phi(x_k) - s \nabla f(x_k)
\end{align*}
which is precisely the form of mirror descent discussed in the previous section.

\subsection{Accelerated Mirror Descent}
Again, leveraging the insights about continuous-time gradient descent, we are able to derive a continuous time accelerated mirror descent ODE. We begin with the Lyapunov function (ref in section 3), and again replace the Euclidean distance with a Bregman divergence on the dual variables. 
\begin{align*} 
\mathcal{E}(X(t),Z(t),t) = \frac{t^2}{r-1} (f(X(t)) - f^*) + (r-1) D_{\phi^*} (Z(t), z^*) \end{align*}
This function is clearly nonnegative, and as above we take the time derivative and set the dynamic such that the function will decrease along trajectories of the system
\begin{align*} 
\dot {\mathcal{E}} &= \frac{2t}{r-1} (f(X(t)) - f^*) + \frac{t^2}{r-1} \langle \nabla f(X(t)), \dot X(t)\rangle + (r-1) \langle \nabla \Phi^* (Z(t)) -  \nabla \Phi^* (z^*), \dot{Z}(t) \rangle\\
&\text{taking }\dot Z = -\frac{t}{r-1} \nabla f(X)\\
\dot {\mathcal{E}} &= \frac{2t}{r-1} (f(X(t)) - f^*) + t \langle \nabla f(X(t)), \frac{t}{r-1} \dot X(t) - (\nabla \Phi^* (Z(t)) -  \nabla \Phi^* (z^*)) \rangle\\
&\text{taking } \nabla \Phi^* (Z) = X + \frac{t}{r-1}\dot X\\
\dot {\mathcal{E}} &= \frac{2t}{r-1} (f(X(t)) - f^*) + t \langle \nabla f(X(t)), x^* - X(t)   \rangle\\
&\leq \frac{2t}{r-1} (f(X(t)) - f^*) + t ( f(X(t))- f(x^*))\\
&= -t \frac{r-3}{r-1} (f(X(t)) - f^*)
\end{align*} 

(rewrite this as a proposition or lemma)?
Then for the chosen dynamics, $V$ is Lyapunov for $r\geq 3$. Ultimately, the proposed ODE system is
\begin{align*}
&\dot X = \frac{r-1}{t} (\nabla \Phi^*(Z) - X)\\
&\dot Z = -\frac{t}{r-1} \nabla f(X)\\
&Z(0) = z_0,~X(0) = \nabla \Phi^*(z_0) := x_0
\end{align*}
By the construction of this system of ODEs as a Lyapunov function, the $1/t^2$ convergence rate is easily proven, using the same logic as (cite previous part), as long as it is assumed that there exist unique solutions $X$ and $Z$. The existence and uniqueness of the solutions to this ODE is nontrivial due to the singularity at $t=0$, the Cauchy-Lipshitz theorem does not apply. The proof relies on construction a sequence that converges to the given function. Details are in the paper \cite{krichene2015accelerated}. Basically, replace $t$ in the denominator with $\max (t,\delta)$ In this process, we assume that $\nabla f$ is $L_f$-Lipschitz. and $\psi^*$ is $L_{\psi^*}$ smooth or equivalently $\nabla \psi^*$ is $L_{\psi^*}$-Lipschitz.

\subsubsection{Continuous-time averaging interpretation}
In integral form, we can write
\[ X(t) = \frac{\int_0^t \tau^{r-1} \nabla\psi^*(Z(\tau)) d\tau}{\int_0^t \tau^{r-1}} \]
So the dual variable $Z$ accumulates gradients with a $\frac{t}{r}$ rate, and primal $X$ is a weighted average of $\nabla\psi^*(Z)$, with weights determined by $t^{r-1}$. Here, it is clear that the primal trajectory remains in $\mathcal X$ because it is convex and $\nabla\psi^*$ maps into $\mathcal X$.

\subsection{Strongly convex case -- new work}
Attempt to write something about this. See if we can prove even a week bound that is vaguely exponential? TODO

\subsection{Discretization}
\subsubsection{Euler scheme}
Mixed forward/backward Euler scheme using step size $\sqrt{s}$ so $t_k = k\sqrt{s}$. (why $k+1$ on the $x$?)
\[ \frac{x_{k+1} - x_k}{\sqrt{s}} = \frac{r}{k\sqrt{s}} (\nabla \psi^*(z_k) - x_{k+1}),\quad \frac{z_{k+1} - z_k}{\sqrt{s}} = -\frac{k\sqrt{s}}{r} \nabla f(x_{k+1}) \]
Simplifying, we get (with $\lambda_k = \frac{r}{r+k}$)
\[ x_{k+1}  = \lambda_k \nabla \psi^*(z_k) + (1-\lambda_k) x_{k}, \quad z_{k+1} = z_k -\frac{ks}{r} \nabla f(x_{k+1}) \]
If we do something special ** with $\psi$ and $\psi^*$ we can recover that for $\tilde z_{k+1} = \nabla \psi^*(z_{k+1} )$
\[ \tilde z_{k+1} = \argmin_{x\in\mathcal{X}} \frac{ks}{r} \langle \nabla f(x_{k+1}), x \rangle + D_\psi (x, \tilde z_k)\]

Then to analyze, start with analogous potential function
\[E_k = V(x_k, z_k, k\sqrt{s}) = \frac{k^2s}{r} (f(x_k) - f^*) + rD_{\psi^*}(z_k,z^*)\]
Through some manipulations, we find that there is an extra term that prevents us from concluding that it is a Lyapunov function. (** with numerical experiments, would this descretized version work?)
\[ E_{k+1} - E_k \leq -\frac{s[(r-2)k-1]}{r} (f(x_{k+1}) - f^*) + rD_{\psi^*}(z_{z+1},z^*) \]

\subsubsection{Proposed discretization}
We make an alteration such that in the $x$ update, we replace $x_k$ with 
\[\tilde x_k = \argmin_{x\in\mathcal X} \gamma s \langle \nabla f(x_k), x \rangle + R(x,x_k)  \]
for a regularization function $R$ *** extend: are there other functions $R$ we could try other than what was proposed here: a distance function $D_\phi (x,x')$. It must be true that $\frac{l_R}{r} \|x-x'\|^2 \leq R(x,x') \leq \frac{L_R}{2} \|x-x'\|^2$
Now $x_{k+1}$ is a combination of a gradient step and a mirror descent update.

... type in full scheme

Then the consistency of this discretization with an extra step holds because $\tilde x_k = x_k + O(s)$

The convergence rate is then shown for an energy function $\tilde E_k = V(\tilde x_k, z_k, k\sqrt{s})$. Should take a closer look at this proof to better understand $\tilde x_k$.

Conditions on this convergence crop up for $\gamma$ and $s$

\subsection{Example and Numerical Experiments}
\subsubsection{Entropic descent: simplex constrained problems}
If we have a simplex constrained problem, we can take $\psi$ to be the negative entropy on a simplex. ***what are another analogous constraints that can be encoded in this way***

The function $\psi$ include $\delta$ to satisfy the constraint, and $\psi^*$ can be computed explicitly. Then mirror descent take $O(n)$ while $\phi^*$ is smooth for l$\infty$. Then take $R(x,y) = D_\phi(x,y)$ for $\phi$ a smoothed negative entropy function. $\nabla \phi^*$ can be computed in $O(n\log n)$, or $O(n)$ for radnomized alg. 

\subsubsection{Numerical Experiments}
Quadratic functoin and log-sum-exp on the simplex problem as above. *** what are applications of the simplex constraint**. Plots show accelerated, non-accelerated, as well as two faster algorithms with restarting mechanisms. 

Looks like there are cool videos in the supplementary material!